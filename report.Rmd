## Introduction  
Utilizing gadgets, for example, Jawbone Up, Nike FuelBand, and Fitbit it is currently conceivable to gather a lot of information about individual movement generally economically. These sort of gadgets are a piece of the evaluated self development â€“ a gathering of devotees who take estimations about themselves consistently to enhance their wellbeing, to discover examples in their conduct, or on the grounds that they are tech nerds. One thing that individuals consistently do is measure how quite a bit of a specific movement they do, yet they infrequently evaluate how well they do it.  

In this task, we will utilize information from accelerometers on the belt, lower arm, arm, and dumbell of 6 members to foresee the way in which they did the activity.  

## Information Preprocessing  
```{r, cache = T}
library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)
library(corrplot)
```
### Download the Data
```{r, cache = T}
trainUrl <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainFile <- "./data/pml-training.csv"
testFile  <- "./data/pml-testing.csv"
if (!file.exists("./data")) {
  dir.create("./data")
}
if (!file.exists(trainFile)) {
  download.file(trainUrl, destfile=trainFile, method="curl")
}
if (!file.exists(testFile)) {
  download.file(testUrl, destfile=testFile, method="curl")
}
```  
### Read the Data
In the wake of downloading the information from the information source, we can read the two csv records into two information outlines.  
```{r, cache = T}
trainRaw <- read.csv("./data/pml-training.csv")
testRaw <- read.csv("./data/pml-testing.csv")
dim(trainRaw)
dim(testRaw)
```
The preparation information set contains 19622 perceptions and 160 variables, while the testing information set contains 20 perceptions and 160 variables. The "classe" variable in the preparation set is the result to foresee. 

### Clean the data
In this step, we will clean the information and dispose of perceptions with missing values and in addition some unimportant variables.
```{r, cache = T}
sum(complete.cases(trainRaw))
```
First and foremost, we uproot sections that contain NA missing qualities.
```{r, cache = T}
trainRaw <- trainRaw[, colSums(is.na(trainRaw)) == 0] 
testRaw <- testRaw[, colSums(is.na(testRaw)) == 0] 
```  
Next, we dispose of a few sections that don't contribute much to the accelerometer estimations.
```{r, cache = T}
classe <- trainRaw$classe
trainRemove <- grepl("^X|timestamp|window", names(trainRaw))
trainRaw <- trainRaw[, !trainRemove]
trainCleaned <- trainRaw[, sapply(trainRaw, is.numeric)]
trainCleaned$classe <- classe
testRemove <- grepl("^X|timestamp|window", names(testRaw))
testRaw <- testRaw[, !testRemove]
testCleaned <- testRaw[, sapply(testRaw, is.numeric)]
```
Presently, the cleaned preparing information set contains 19622 perceptions and 53 variables, while the testing information set contains 20 perceptions and 53 variables. The "classe" variable is still in the cleaned preparing set.

### Slice the data
At that point, we can part the cleaned preparing set into an unadulterated preparing information set (70%) and an acceptance information set (30%). We will utilize the acceptance information set to lead cross approval in future steps.  
```{r, cache = T}
set.seed(22519) # For reproducibile purpose
inTrain <- createDataPartition(trainCleaned$classe, p=0.70, list=F)
trainData <- trainCleaned[inTrain, ]
testData <- trainCleaned[-inTrain, ]
```

## Data Modeling
We fit a prescient model for movement acknowledgment utilizing **Random Forest** calculation in light of the fact that it consequently chooses critical variables and is vigorous to corresponded covariates & exceptions when all is said in done. We will utilize **5-fold cross validation** when applying the calculation.  
```{r, cache = T}
controlRf <- trainControl(method="cv", 5)
modelRf <- train(classe ~ ., data=trainData, method="rf", trControl=controlRf, ntree=250)
modelRf
```
At that point, we appraise the execution of the model on the acceptance information set.
```{r, cache = T}
predictRf <- predict(modelRf, testData)
confusionMatrix(testData$classe, predictRf)
```
```{r, cache = T}
accuracy <- postResample(predictRf, testData$classe)
accuracy
oose <- 1 - as.numeric(confusionMatrix(testData$classe, predictRf)$overall[1])
oose
```
In this way, the evaluated exactness of the model is 99.42% and the assessed out-of-test mistake is 0.58%.

## Predicting for Test Data Set
Presently, we apply the model to the first testing information set downloaded from the information source. We evacuate the `problem_id` section first.
```{r, cache = T}
result <- predict(modelRf, testCleaned[, -length(names(testCleaned))])
result
```  

## Appendix: Figures
1. Correlation Matrix Visualization  
```{r, cache = T}
corrPlot <- cor(trainData[, -length(names(trainData))])
corrplot(corrPlot, method="color")
```
2. Decision Tree Visualization
```{r, cache = T}
treeModel <- rpart(classe ~ ., data=trainData, method="class")
prp(treeModel) # fast plot
```
